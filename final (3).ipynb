{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ld6OrnLmD6JM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "import numpy as np\n",
        "import math\n",
        "import torchvision\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAk_QERsrsCN",
        "outputId": "0ba10aa3-37d3-4ad5-b88a-352c39e7f5f1"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr --quiet\n",
        "import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/jayanth.kumar/Desktop/work/Hackverse/GTSRB/yolov7\n"
          ]
        }
      ],
      "source": [
        "%cd yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL6E73YkDze1",
        "outputId": "e37baa53-d3e9-439a-e364-c90f3b3fdb2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'yolov7' already exists and is not an empty directory.\n",
            "/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy/yolov7\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EB5rOfT3EFVk"
      },
      "outputs": [],
      "source": [
        "from models.experimental import attempt_load\n",
        "from utils.general import check_img_size, non_max_suppression, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.torch_utils import time_synchronized\n",
        "from utils.datasets import letterbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3NVBc2GaEGCt"
      },
      "outputs": [],
      "source": [
        "def detect(model, source):\n",
        "\n",
        "    device = 'cpu'\n",
        "    imgsz = 640\n",
        "    img = source\n",
        "\n",
        "\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check img_size TODO\n",
        "\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    old_img_w = old_img_h = imgsz\n",
        "    old_img_b = 1\n",
        "    im0 = img\n",
        "\n",
        "        # Convert\n",
        "    img = letterbox(img, imgsz, stride=stride)[0]\n",
        "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "    img = np.ascontiguousarray(img)\n",
        "\n",
        "\n",
        "    img = torch.from_numpy(img).to(device)\n",
        "    img = img.float()  # uint8 to fp16/32\n",
        "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "    if img.ndimension() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
        "        pred = model(img)[0]\n",
        "    # Apply NMS\n",
        "    pred = non_max_suppression(pred, 0.25, 0.45, classes=[0,1,2,3,4,5])\n",
        "\n",
        "    # Process detections\n",
        "    outputs = []\n",
        "    for i, det in enumerate(pred):  # detections per image\n",
        "\n",
        "        if len(det):\n",
        "\n",
        "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "            for *xyxy, conf, cls in reversed(det):\n",
        "                label = f'{names[int(cls)]}'\n",
        "                out = [t.item() for t in xyxy]\n",
        "                outputs.append((out, label, conf.item()))\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def crop_image(out, img):\n",
        "  x1 = int(out[0][0])\n",
        "  x2 = int(out[0][2])\n",
        "  y1 = int(out[0][1])\n",
        "  y2 = int(out[0][3])\n",
        "  print(x1, x2, y1, y2)\n",
        "  # Cropping an image\n",
        "  cropped_image = img[y1:y2, x1:x2]\n",
        "\n",
        "  return cropped_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7JV1tBFr1VK",
        "outputId": "19622b44-df37-40ab-a0b5-48c915872978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1qXBtVeOpZjeY-AduqtyTtu22y6RytGeO\n",
            "From (redirected): https://drive.google.com/uc?id=1qXBtVeOpZjeY-AduqtyTtu22y6RytGeO&confirm=t&uuid=5557e4e1-01d7-4008-9bf5-1591fec3df55\n",
            "To: /Users/jayanth.kumar/Desktop/work/Hackverse/GTSRB/yolov7/classify.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74.8M/74.8M [00:06<00:00, 11.0MB/s]\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1Ni_w3QCucfHI271ASUjk7k04GZseGJcz\n",
            "From (redirected): https://drive.google.com/uc?id=1Ni_w3QCucfHI271ASUjk7k04GZseGJcz&confirm=t&uuid=b3263093-b03e-422e-9671-4c5822d041eb\n",
            "To: /Users/jayanth.kumar/Desktop/work/Hackverse/GTSRB/yolov7/segmentation.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74.8M/74.8M [00:09<00:00, 8.07MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet\n",
        "!gdown 1qXBtVeOpZjeY-AduqtyTtu22y6RytGeO\n",
        "!gdown 1Ni_w3QCucfHI271ASUjk7k04GZseGJcz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy9dZv8LGVWV",
        "outputId": "f7bdf081-c348-47c1-cb66-914dcc88c1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "model1 = attempt_load('/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy1/new1/midprep-cloudphy/segmentation.pt')\n",
        "model2 = attempt_load('/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy1/new1/midprep-cloudphy/classify.pt')\n",
        "reader = easyocr.Reader(['en'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy/seg-split/train/images/hcgbhavnagar_micu_mon--403_2022_5_18_9_20_0.jpeg', update=False, view_img=False, weights=['/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy1/new1/midprep-cloudphy/classify.pt'])\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 2.0.0 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/Users/jayanth.kumar/opt/anaconda3/envs/cloudphy/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36523006 parameters, 6194944 gradients, 103.3 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1 HR_W, 1 SPO2_W, Done. (1951.9ms) Inference, (2.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp9/hcgbhavnagar_micu_mon--403_2022_5_18_9_20_0.jpeg\n",
            "Done. (1.997s)\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights /Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy1/new1/midprep-cloudphy/classify.pt --conf 0.25 --img-size 640 --source /Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy/seg-split/train/images/hcgbhavnagar_micu_mon--403_2022_5_18_9_20_0.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4y9pzjtoawdV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def inference(image_path:str):\n",
        "  '''\n",
        "  Function responsible for inference.\n",
        "  Args: \n",
        "    image_path: str, path to image file. eg. \"input/aveksha_micu_mon--209_2023_1_17_12_0_34.jpeg\"\n",
        "  Returns:\n",
        "    result: dict, final output dictionary. eg. {\"HR\":\"80\", \"SPO2\":\"98\", \"RR\":\"15\", \"SBP\":\"126\", \"DBP\":\"86\"}\n",
        "  '''\n",
        "  result = {}\n",
        "  img = cv2.imread(image_path)\n",
        "  \n",
        "  out1 = detect(model1, img)\n",
        "  out1_img = crop_image(out1[0], img)\n",
        "  cv2.imwrite(\"./outpic.jpeg\", out1_img)\n",
        "\n",
        "  out2 = detect(model2, out1_img)\n",
        "  temp = {}\n",
        "\n",
        "  \n",
        "  \n",
        "  for out in out2:\n",
        "    out2_img = crop_image(out, out1_img)\n",
        "\n",
        "    r = reader.readtext(out2_img)\n",
        "    if(not r):\n",
        "      continue\n",
        "    r = r[0]\n",
        "\n",
        "    if(r[2] < 0.2):\n",
        "      continue\n",
        "\n",
        "    tt = temp.get(out[1])\n",
        "    if(tt):\n",
        "      if tt['class_conf'] > out[2]:\n",
        "        continue\n",
        "\n",
        "\n",
        "    temp[out[1]] = {\n",
        "          'class_conf': out[2],\n",
        "          'value': re.sub(\"[^0-9]\", \"\", r[1]),\n",
        "          'value_conf': r[2]\n",
        "      }\n",
        "\n",
        "  l = ['HR', 'SPO2', 'RR', 'SBP', 'DBP', 'MAP']\n",
        "\n",
        "  for i in l:\n",
        "    if(not temp.get(i)):\n",
        "      continue\n",
        "\n",
        "    result[i] = temp[i]['value']\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "345 836 157 498\n",
            "67 100 329 341\n",
            "145 171 323 341\n",
            "387 419 47 77\n",
            "415 450 252 282\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'HR': '67', 'RR': '10'}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference(\"/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy/seg-split/val/images/hcgbhavnagar_micu_mon--403_2022_5_18_13_20_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def temp1(image_path:str):\n",
        "  '''\n",
        "  Function responsible for inference.\n",
        "  Args: \n",
        "    image_path: str, path to image file. eg. \"input/aveksha_micu_mon--209_2023_1_17_12_0_34.jpeg\"\n",
        "  Returns:\n",
        "    result: dict, final output dictionary. eg. {\"HR\":\"80\", \"SPO2\":\"98\", \"RR\":\"15\", \"SBP\":\"126\", \"DBP\":\"86\"}\n",
        "  '''\n",
        "  result = {}\n",
        "  img = cv2.imread(image_path)\n",
        "  \n",
        "  out1 = detect(model1, img)\n",
        "  out1_img = crop_image(out1[0], img)\n",
        "\n",
        "  img = Image.fromarray(out1_img, 'RGB')\n",
        "  img.save('my.png')\n",
        "  img.show()\n",
        "  \n",
        "  out2 = detect(model2, out1_img)\n",
        "  temp = {}\n",
        "  \n",
        "  for out in out2:\n",
        "    out2_img = crop_image(out, out1_img)\n",
        "    print(type(out2_img))\n",
        "    img = Image.fromarray(out2_img, 'RGB')\n",
        "    img.save('my.png')\n",
        "    img.show()\n",
        "\n",
        "temp1(\"/Users/jayanth.kumar/Desktop/work/Hackverse/midprep-cloudphy/seg-split/val/images/hcgbhavnagar_micu_mon--403_2022_5_18_13_20_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cloudphy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16 (default, Mar  1 2023, 21:19:10) \n[Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b97cb24927c0057e497a1fd4c90f92a33d8ccea95bdda4a28f0d0c6792b1f284"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
